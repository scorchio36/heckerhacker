{
  "terms":
    {
      "adsr": {
          "word": "ADSR Envelope",
          "definition": "ADSR stands for Attack, Delay, Sustain, and Release. This refers to parts of an envelope signal that you can customize. This envelope is then used to modulate a parameter of another signal. Typically you use it to modulate the amplitude of a signal or the cutoff frequency of a filter. But most DAWs or synths should really allow you to modulate any parameter that you want with the envelope. The names Attack, Delay, Sustain, and Release refer to sections of this envelope and you can adjust each section to change how the parameter you are modulating is modulated. The envelope amplitude begins at zero and rises up to an initial peak. The time it takes for the envelope to rise from 0 and hit this peak is called the attack. The envelope amplitude then immediately falls from this peak and down to a sustain level. The delay is how long it takes the envelope to fall from the envelope peak to the sustain amplitude. You can adjust the sustain to be at whatever level you would like. Finally, the release is how long it takes the envelope to fall from the sustain back to 0. Depending on the envelope, there could be additional sections like pre-delay (time between t=0 and the start of the attack section) or hold (how long to hold the peak of the envelope). You can use this envelope to create cool effects if you're modulating amplitude. You could create a strumming or string effect out of a sustained instrument by having a very quick delay that falls down to a near-zero sustain level. You could create a peakless, wah sound that sounds like a note played in reverse, if you lengthen the attack time. You can use envelopes many creative ways. That is just brushing the surface.",
          "links": [
            {
              "title": "ADSR Envelopes",
              "link": "https://www.wikiaudio.org/adsr-envelope/"
            }
          ]
      },
      "audiointerface": {
          "word": "Audio Interface",
          "definition": "A piece of hardware that acts as an 'in-between' for the digital and analog sides of your sound production setup. Your computer lives in sample land. It operates strictly on digital files and formats. The real world is analog. Guitars, microphones, drums, etc all produce analog signals. These real-world analog signals need to be turned into digital signals in order for your computer to operate on them. Some computer motherboards have some audio hardware built-in, but it's typically not going to be enough if you seriously want to produce and record music. A motherboard will lack many of the interfaces/ports you may need and the DAC/ADCs may not be as good as the ones dedicated to audio measurement and production. That's where an audio interface comes in. Audio interfaces allow for analog instruments and transducers like microphones to be plugged in. They have a variety of options like TS, TRS, and XLR for receiving input. They should also offer things like pre-amplification and phantom power. Audio interfaces also have outputs, which can connect to speakers and headphones. Audio interfaces will take analog-signals from the real world, convert them to digital with a high-quality ADC (Analog to Digital Converter). The reverse is also true. They also take the digital signals from the computer and use a DAC (Digital to Analog Converter) and send analog signals out to drive speakers and headphones.",
          "links": [
            {
              "title": "Focusrite Scarlett Solo 3rd Gen - REVIEW",
              "link": "https://www.youtube.com/watch?v=VSgzF79ivd0&t=288s&ab_channel=JulianKrause"
            },
            {
              "title": "How to choose the best audio Interface for home studio recording",
              "link": "https://www.youtube.com/watch?v=7QOXjfB1ExM&ab_channel=PeteJohns-StudioLiveToday"
            }
          ]
      },
      "compressor": {
          "word": "Compressor",
          "definition": "Compressors are tools that control the dynamics of a sound or mix. The main reason you use them is to squash down transients so you have more control over your audio levels. Sounds can be unruly and inconsistent. For a lot of audio sources, like vocals, there is a large disparity between the loudest and quietest sounds that a singer produces (the difference in dB between the loudest and quietest levels in a mix is called the Dynamic Range). This can lead to an inconsistent feeling from a mix or sound. It also causes a problem of balancing. The quiet sounds may be too hard to hear, but turning up the whole track can make your loudest sounds clip. The compressor is a good tool for this. It has two main controls that can be adjusted: the threshold and the ratio. The threshold is set at a certain dB level. If any portion of a sound goes above this dB level, then the compressor will kick in and attenuate the portion of the sound that exceeds the threshold. But how do you control how much the sound gets attenuated? Through the ratio parameter. The ratio is an X:1 ratio where X determines how many decibels of attenuation a signal experiences per dB of signal that crosses the threshold. For example, if my ratio is 4:1 and my threshold is -14dB, every 4dB that crosses the -14dB threshold is squashed down to 1dB. If I have a -10dB signal pumping through this compressor, it will be squashed down to -13dB. A -6dB signal would be attenuated to -12dB. There are two other parameters that are worth mentioning. The attack and release levels. These are set in milliseconds. They are used to tell the compressor how much time it should wait before kicking in or cutting out. When a signal crosses the threshold parameter, the attack is the amount of time the compressor should wait before it starts attenuating the signal. When a signal drops back below the threshold level, the release is the amount of time the compressor should keep attenuating the signal before it shuts off again. Compressors are used for dynamic control, but they are also appreciated for the tonal value that they can add to a sound. Each compressor has an intrinsic effect that it applies to a sound through signal processing. Most processors/VSTs do. The effect is different for every compressor. But you can also affect the tone of an incoming signal by adjusting any of the 4 parameters mentioned earlier. The compressors main goal is not to change the tonal value of your signal, so these sound changes are subtle. They can change the punch of a sound, make a sound more thick or thin. They can be applied to a whole bus or mix to 'glue' sounds together.",
          "links": [
            {
              "title": "FL STUDIO | Mixing Basics - Compression",
              "link": "https://www.youtube.com/watch?v=gJUmUd4FfeM&list=PLkYsB0Ki9lAdIaYCpB0B0uVTZMZBt9NdX&index=3&ab_channel=FLSTUDIObyImage-LineSoftware"
            },
            {
              "title": "Wikiemedia - Dynamics Playlist (Youtube)",
              "link": "https://www.youtube.com/watch?v=NVxbx3ixLYA&list=PLB116FE339C48F0A1&ab_channel=wickiemedia"
            },
            {
              "title": "Are You Listening? Season 1 with Johnathan Wyner - Compression in Mastering (Youtube)",
              "link": "https://www.youtube.com/watch?v=IyjlRiNiLBg&t=786s&ab_channel=iZotope%2CInc."
            },
            {
              "title": "Musician on a Mission - Compressors",
              "link": "https://www.musicianonamission.com/curation/subtax_compression/"
            },
            {
              "title": "In the Mix - How To Use Compression - Detailed Tutorial",
              "link": "https://www.youtube.com/watch?v=yi0J9JsRdI4&list=PLx5i827-FDqOYGlVKM58mXnMV-rET--LL&index=3&ab_channel=InTheMix"
            }
          ]
      },
      "condensormic": {
          "word": "Condensor Microphone",
          "definition": "Condensor mics uses a capacitor to measure sound. One plate is anchored while the other is allowed to move based on the sound waves that hit it. The varying distances between the plates create varying voltages. Condensors can pick up much more detail than dynamic mics and they typically have a much flatter frequency response, especially at higher frequencies. Take care as some condensor mics can start distorting if the sound source is getting too loud. Typically, you'd want to switch to a dynamic mic in that situation. Condensor mics also require an external power source, usually called 'phantom power'. The required voltage can range anywhere form 40V to 80V. A common phantom power is 48V.",
          "links": [
            {
              "title": "Audio Recording Tutorial - Comparing microphone types",
              "link": "https://www.youtube.com/watch?v=2edewYkE_f0&ab_channel=LinkedInLearning"
            },
            {
              "title": "Roswell Pro Audio - How Condenser Mics Work",
              "link": "https://www.youtube.com/watch?v=pD-zqqgLjJA&ab_channel=RoswellProAudio"
            },
            {
              "title": "Edward Smith - Best BUDGET Microphones For Vocals (2022) ",
              "link": "https://www.youtube.com/watch?v=BUa2GttUfbs&t=220s&ab_channel=EdwardSmith"
            }
          ]
      },
      "daw": {
          "word": "Digital Audio Workstation (DAW)",
          "definition": "A computer application with features that allow you to create, edit, and publish music digitally. This is where you will do all of your work when creating a song. They generally come with built in tools (called stock plugins) like compressors, equalizers, synths, etc. But they also have options for you to import 3rd party VSTs. Different DAWs will have some variation in what stock plugins they offer, the workflow, whether you can edit vocals, etc, but ultimately, most DAWs can do whatever other DAWs can do as well. Some examples of DAWs include FL Studio, LMMS, Logic Pro, and Ableton.",
          "links": [
            {
              "title": "LMMS",
              "link": "https://lmms.io/"
            },
            {
              "title": "FL Studio",
              "link": "https://www.image-line.com/fl-studio/"
            },
            {
              "title": "Ableton",
              "link": "https://www.ableton.com/"
            },
            {
              "title": "Logic Pro",
              "link": "https://www.apple.com/logic-pro/"
            }
          ]
      },
      "digitalsweetspot": {
          "word": "Digital Sweet Spot",
          "definition": "Digital VST instruments and plugins today are generally modeled after analog instrumentation from the 'olden days' of music. There was typically a spot, at 0VU, that was known as the analog sweet spot. That is where you wanted your signals to be for processing so they would sound best. This is still the case for digital instruments, since most of them are modeled after the analog ones. Processing is most effective if you have your signal levels at 0VU, which is around -18dbFS. Getting your input sounds into this digital sweet spot before processing usually falls under the concept of 'gain staging'. You can use a VU meter and change the gain of the loudest part of a track until it, on average, hovers around 0VU. This is easier for sustained notes. For more dynamic notes, you should be more concerned with the peak. Get as close as you can to 0VU without compromising the amount of headroom you want to ultimately leave in your track.",
          "links": [
            {
              "title": "The Digital Audio Sweet Spot (RecordingRevolution)",
              "link": "https://www.youtube.com/watch?v=1hxMidhTLa8&ab_channel=recordingrevolution"
            },
            {
              "title": "A Complete Guide to Gain Staging (your questions answered)",
              "link": "https://www.youtube.com/watch?v=Tq5lDHCKt84&ab_channel=MusicianonaMission"
            }
          ]
      },
      "dynamicmic": {
          "word": "Dynamic Microphone",
          "definition": "Dynamic microphones are robust mics that are better for recording louder sounds and live performances. The microphone has a diaphragm connected to a coil of wire. The pressure generated by sound waves moves the diaphragm and thereby the wire up and down. The coil is centered around a permanent magnet that generates a voltage within the coil of wire based on how quickly and loudly the diaphragm is displaced. These mics are considered 'heavy', so it takes a lot of energy to move that diaphragm up and down. That's typically why they are used for louder recordings.",
          "links": [
            {
              "title": "Audio Recording Tutorial - Comparing microphone types",
              "link": "https://www.youtube.com/watch?v=2edewYkE_f0&ab_channel=LinkedInLearning"
            },
            {
              "title": "Roswell Pro Audio - How Dynamic Mics Work",
              "link": "https://www.youtube.com/watch?v=PFgUoGJ7YbA&ab_channel=RoswellProAudio"
            }
          ]
      },
      "ducking": {
          "word": "Ducking",
          "definition": "When you duck a sound out of your music, you soften or completely zero the amplitude of that sound for a certain period of time. This is typically done to allow for another sound to cut through your mix. A good example of this is the kick and bass within a mix. A kick is a short burst of sound that typically has a lot of energy in the lower part of the spectrum (sub-bass, bass, low-mids). Let's imagine that we have a sustained bass note throughout the mix, which also has a lot of energy in the sub-bass and bass portions of the spectrum. The frequency content of the kick and the bass will clearly overlap and mess with each other. This can cause clarity and phase problems as the two sounds constructively and destructively interfere. You will have a lot of issues hearing your kick through the bass and the track will sound muddy. A good fix for this is to 'duck' out the bass everytime the kick hits. This will allow your kick to cut through the bass and make it much easier to hear. You can duck out the bass in a subtle way - just enough for that kick to cut through. Or you can duck out the bass by a lot and introduce a pumping effect into your mix. The example given is typically done through side chaining, but can also be done with an LFO. See 'sidechaining' in the vocab section and LFO vs Compressors in the notes section.",
          "links": [
            {
              "title": "What is SideChaining (Introduces the term Ducking)",
              "link": "https://ledgernote.com/columns/mixing-mastering/what-is-sidechaining/"
            },
            {
              "title": "LMMS Forum: Using a Peak Controller for Ducking/Sidechaining",
              "link": "https://lmms.io/forum/viewtopic.php?t=1181"
            }
          ]
      },
      "equalizer": {
          "word": "Equalizer (EQ)",
          "definition": "Equalizers give you fine control over the frequency content of a track or sound. It is a collection of low pass, high pass, band pass, and band stop, and shelf filters that are used to boost or cut any portion of the frequency spectrum. This can be used for four main reasons. To clean up crappy parts of a recording/sample, to accentuate the nice parts of a sound, to create space for other elements in a mix, or to just change the sound/timbre of an instrument.",
          "links": [
            {
              "title": "FL STUDIO | Mixing Basics - Equalization",
              "link": "https://www.youtube.com/watch?v=lNKVYFzbzOc&list=PLkYsB0Ki9lAdIaYCpB0B0uVTZMZBt9NdX&index=2&ab_channel=FLSTUDIObyImage-LineSoftware"
            },
            {
              "title": "How to Use EQ: 10 Amazing Tips for a Professional Mix",
              "link": "https://www.musicianonamission.com/approach-equalization-two-types-eq/"
            },
            {
              "title": "The Ultimate EQ Cheat Sheet for Every Common Instrument",
              "link": "https://blog.sonicbids.com/the-ultimate-eq-cheat-sheet-for-every-common-instrument"
            }
          ]
      },

      "gainautomation": {
          "word": "Gain Automation",
          "definition": "Gain automation is another 'chery on top' technique that you can use to set your mix apart. Gain automation is when you use automation within your DAW to alter the gain (incoming signal before processing) of your signal in certain parts of the track. The idea here is to reduce the dynamic range of a track so that compression and your track become more consistent. You usually want to bring up lower energy portions of your track and bring down the higher energy ones so that you have an overall average energy that is the same throughout the whole track. This is a really good technique to use with compression, if it is done right. However, don't think that this is something you should do to every individual track and sample you have. In fact, you probably shouldn't. You need to make an artistic choice, because sometimes your mix will sound better with that higher dynamic range. Sometimes you really just want that peak to punch through or you want to create space with a quieter channel. There is a compromise between these two choices however. You can do gain automation to bring parts of your track up or down. But then, you can use volume automation to compensate for some of that dynamic range that you lost out on. This will obviously still alter your sound, but it is an option that you have.",
          "links": [
            {
              "title": "Gain Automation (The Secret Sauce of Compression)",
              "link": "https://www.youtube.com/watch?v=aun6XN63Jvo&ab_channel=MusicianonaMission"
            }
          ]
      },

      "gainstaging": {
          "word": "Gain Staging",
          "definition": "Analog studio technology was built to process signals most effectively at 0dBVU. This value is referred to as the 'analog sweet spot'. Today's digital processing equipment and VSTs were based on these legacy analog processors, so 0dBVU is still the best place for an incoming signal to sit before processing. Therefore, before mixing, it is a good idea to adjust the gain of your track such that the loudest part of the track averages around 0dBVU. Please note that this is not a strict requirement. Some instruments are more dynamic, so it makes no sense for them to 'average' 0dBVU. In that case, you should try and get them to peak at 0dBVU. Additionally, for some instruments, like drums, it may not be possible for you to hit 0dBVU without clipping. For these hyper-dynamic instruments, you would be better suited to get as close to 0dBVU as you can without clipping. But make sure to still leave yourself some headroom. The whole point of this is to set your tracks up for processing. If your tracks are sitting around 0dBVU, then they will sound their best as they are processed by something like a compressor or equalizer. This whole process of adjusting your track gains before mixing in order to hit this 'analog sweet spot', is my preferred definition for gain staging. For some reason gain staging was one of the most confusing things to learn about. It seems like there's so many definitions for gain staging and a lot of people have different opinions about how it should be done or what it even is. The closest happy definition that I have found, is that gain staging, is anything that you do to control the levels throughout your mixing process at any point in the signal chain or mix. The goal here is make mixing an easier process. You want to control your levels so that you do not clip at any point within your signal chain. However, you also want to make sure all the elements in your mix are properly balanced and have the right energy so they are not lost or coming in too hot in the rest of the mix. There are a couple of other definitions that I have found for gain staging. One is the idea that your processors should not add any gain to your tracks. If you have an X dBVU sound going into a processing VST, then X dBVU should be coming out. This has to do with the fact that louder sounds sound better to our ears. So you want to make sure that the sound coming out sounds better because of the processor - not just because it's louder. The idea of adjusting the makeup gains of VSTs within your processing chain so that the output signal has the same dBVU as the input signal, is also something that I've seen fall under the idea of gain staging. One other definition I have seen for gain staging is relevant to actually recording songs with real instruments and singers. The various techniques that you can do during recording to make sure your recordings don't clip and are ready for processing can also be referred to as gain staging. I can't really go too in depth here, as I don't have much experience with physically recording instruments and people. Although definitions can vary widely, gain staging, at the end of the day, is just adjusting the gain of your tracks and processing chain to make sure your tracks can be processed effectively and sound their best.",
          "links": [
            {
              "title": "Gain Staging: What it is and How to Do it.",
              "link": "https://www.izotope.com/en/learn/gain-staging-what-it-is-and-how-to-do-it.html"
            },
            {
              "title": "What is Gain Staging and How it Can Improve your Mix.",
              "link": "https://cymatics.fm/blogs/production/what-is-gain-staging"
            },
            {
              "title": "Gain Staging: Supercharge your Mix with these Simple Steps.",
              "link": "https://www.musicianonamission.com/gain-staging/"
            },
            {
              "title": "(MusicianOnAMission) A Complete Guide to Gain Staging (your questions answered)",
              "link": "https://www.youtube.com/watch?v=Tq5lDHCKt84&ab_channel=MusicianonaMission"
            },
            {
              "title": "Gain Staging Like a Pro",
              "link": "https://www.sweetwater.com/insync/gain-staging/"
            },
            {
              "title": "Gain Staging: Secret to Get Good Levels in Your Mix",
              "link": "https://www.recordingbase.com/gain-staging/"
            }
          ]
      },

      "gain": {
          "word": "Gain",
          "definition": "Gain is the level of a signal (generally in dB) before it goes through a signal chain (before all of your processing). This is essentially the raw level of your incoming sample or individual track. Most DAWs have a knob or something that let's you control this gain. When you move the knob you are altering the file/sample itself. Contrast this with volume, which is the level of the signal after going through the signal chain. It is important to note that this is a contextual definition. Not everyone will go by this convention and volume and gain can be used interchangebly and to label different things. This distinction between volume and gain is good to have when you're doing something like gain staging.",
          "links": [
            {
              "title": "A Complete Guide to Gain Staging",
              "link": "https://www.youtube.com/watch?v=Tq5lDHCKt84&t=133s&ab_channel=MusicianonaMission"
            }
          ]
      },

      "haaseffect": {
          "word": "Haas Effect",
          "definition": "The Haas Effect is artifical perceived directionality of a sound within a stereofield created by delaying the same sound on the left and right stereo channels. You can make a person detect a sounds as coming from the right or left by messing around with the timing of the same sound on both channels. Note that this is different from panning. Panning affects the dB of the same sound on the left or right stereo channels. Haas effect is related to the timing of the same sound on either channel, rather than the level.",
          "links": [
            {
              "title": "Sage Audio - How to Use the Haas Effect",
              "link": "https://www.sageaudio.com/blog/pre-mastering/use-haas-effect.php"
            },
            {
              "title": "FL STUDIO | Mixing Basics - Stereo Field",
              "link": "https://www.youtube.com/watch?v=UWW-ppRjmCQ&list=PLkYsB0Ki9lAdIaYCpB0B0uVTZMZBt9NdX&index=4&ab_channel=FLSTUDIObyImage-LineSoftware"
            }
          ]
      },

      "layering": {
            "word": "Layering",
            "definition": "Stacking and combining different sounds on top of each other in order to create a more interesting, fuller, and cohesive sound. Mastering this technique will make your musical productions sound much more professional and 'larger-than-life'.",
            "links": [
              {
                "title": "Hyperbits - Layering Music: 20 Ways to Layer Sounds",
                "link": "https://hyperbits.com/layering-sounds/"
              }
            ]
        },

      "legato": {
            "word": "Legato",
            "definition": "In music performance and notation, legato indicates that musical notes are played or sung smoothly and connected.",
            "links": [
              {
                "title": "Video with sound demonstration",
                "link": "https://www.youtube.com/watch?v=JgJcKt92vt8&ab_channel=LearnPianoCompleteGuide"
              },
              {
                "title": "Legato-Wikipedia",
                "link": "https://en.wikipedia.org/wiki/Legato"
              }
            ]
        },

        "lfo": {
              "word": "Low Frequency Oscillator (LFO)",
              "definition": "A general-purpose waveform generator that can be used to modulate parameters within a synth or a DAW. Some examples of uses for an LFO are creating a tremolo effect with a pitch shifter, ducking out the bass by driving an attenuator with the LFO so the kick can punch through, or moving the cutoff frequency of a filter back and forth across a range of the spectrum. LFOs really versatile and a use can be found for them in practically every aspect of music production. Although they can have frequencies that exceed this range by a bit, LFOs are usually not more than 10Hz-20Hz. The LFO has two main adjustments/controls. The depth and the frequency. The depth is just another word for the amplitude of the waveform generated by the LFO. It basically determines how much of an influence the LFO has on the parameter that is being modulated. The other parameter, frequency, controls how rapidly the modulated parameter changes.",
              "links": []
        },
        "mid": {
              "word": "Mid",
              "definition": "(This is the definition for 'mid' in the context of stereo mixing. A large portion of the stereo spectrum can also be referred to as the mids - typically from around 200Hz to 3-6KHz, further subdivided in to the low mids, mids, and high mids). When mixing in stereo, mid is the audio that is exactly the same in both channels. The sameness in sound manifests itself as a strong, 'mono-wall' that seems to play right in front of you within the stereo field. This is antithetical to the 'side' within the stereo field. The side is all the sounds that are different between the Left and Right stereo channels. The side creates more stereo width and is the space where the listener hears variations in sounds and timing between the left and right ear.",
              "links": [
                {
                  "title": "Izotope - Stereo Imaging in Mastering: Width and Mid/Side | Are You Listening? | S2 Ep1",
                  "link": "https://www.youtube.com/watch?v=0tqlHNuacik&ab_channel=iZotope%2CInc."
                },
                {
                  "title": "In the Mix - Mid Side EQ Simplified - A Powerful Tool for Stereo Mixing",
                  "link": "https://www.youtube.com/watch?v=kEiILPm1VSc&ab_channel=InTheMix"
                }
              ]
        },
        "modulation": {
              "word": "Modulation",
              "definition": "Controlling a parameter of a signal or waveform with the amplitude of another signal or waveform. An example of modulation is amplitude modulation, where the amplitude of a signal changes based on another waveform's amplitude. You can have phase modulation, where the phase of a signal changes based on another input signal's current amplitude. You can have frequency modulation, where the (you guess it) frequency of a waveform is controlled by another signal. This can be used for automation, creating cool effects, creating different sounds, etc.",
              "links": []
        },
        "multibandcompression": {
              "word": "Multiband Compression",
              "definition": "Multiband compressors allow you to have different compression settings for different bands within the frequency spectrum. Imagine you're mixing vocals and a vocalist has some strange artifacts and large peaks going on in the low end. You want to dull the dynamics out a bit on the low-end so they're not drowning out the mid and high-end of the spectrum. You could use a regular compressor to push those low-end peaks down, but anytime the compressor sees one of those large peaks, it's going to squash don't the entire vocal range as a whole. Your high-end will start to duck out when the low peaks hit and it will cause some strange effects in the vocals. Instead, you can use a multiband compressor to only compress the low end peaks. This will allow you to squash down those strange artifacts while leaving the dynamics of the mids and high-end intact.",
              "links": [
                {
                  "title": "In the Mix - Are You Using This Multiband Compression Trick?",
                  "link": "https://www.youtube.com/watch?v=gg2xN8_dcW0&list=PLx5i827-FDqOYGlVKM58mXnMV-rET--LL&index=2&ab_channel=InTheMix"
                }
              ]
        },

        "pad": {
              "word": "Pad or Pad Synth",
              "definition": "A sustained sound that is used to add thickness and atmosphere to a mix or composition. The sound is typically made up of stacked instruments or synths. Additionally, a unison effect can be used to widen the frequency spread of the sound, so the sound has more of an impact. The idea is to fill up the room with, what I would call, 'warmth'. You want the pad to fill in all the open space in a mix or composition, so you get a more full effect.",
              "links": [
                {
                  "title": "Why is a Synth Pad called a Pad?",
                  "link": "https://musicianshq.com/why-is-a-synth-pad-called-a-pad"
                }
              ]
          },
        "pan": {
              "word": "Pan",
              "definition": "Knob used to control where a track sits in the stereoscopic field. By default, sounds will be directly in front of you in the middle of the stereo view. You can pan right or left by a percentage from -100% to 100% to change how much the 'instrument' will sit to the left or right relative to the listener. Don't be afraid to add some automation to panning. A good way to add life and keep your song from getting boring is to play around with where your instruments sit during bigger parts of the song.",
              "links": [
                {
                  "title": "FL STUDIO | Mixing Basics - Stereo Field",
                  "link": "https://www.youtube.com/watch?v=UWW-ppRjmCQ&list=PLkYsB0Ki9lAdIaYCpB0B0uVTZMZBt9NdX&index=4&ab_channel=FLSTUDIObyImage-LineSoftware"
                }
              ]
        },

        "patch": {
              "word": "Patch",
              "definition": "A patch is a configuration of a synth that gives you a particular sound. The positions of the all the knobs, sliders, and oscillators used to create a sound would be referred to as the patch that's used to create that sound. This is the noun definition. Don't confuse this with the verb, to patch. See definition for patching, below.",
              "links": []
        },

        "patching": {
              "word": "Patching",
              "definition": "This is the process of routing a sound from one piece of audio hardware to another, typically by means of some sort of audio jack and cable. Not to be confused with a synth patch.",
              "links": []
        },

        "pitchbending": {
              "word": "Pitch Bending",
              "definition": "Using automation to slide the pitch of a note or sample to a different pitch. This creates a really cool effect in EDM. Different DAWs have different names for this. This is 'note sliding' in FL Studio.",
              "links": [
                {
                  "title": "Reddit - PITCH BEND and its USES in EDM",
                  "link": "https://www.reddit.com/r/edmproduction/comments/1sb5q2/pitch_bend_and_its_uses_in_edm/"
                },
                {
                  "title": "Awesome example of Harsh Pitch Bending in a Song",
                  "link": "https://www.youtube.com/watch?v=mWpfc6SwJrA&t=60s"
                }
              ]
          },

        "portamento": {
            "word": "Portamento",
            "definition": "Portamento is a type of legato and it means sliding from one note to the next (kind of like a slide whistle). When using it on a synth, play a note normally first. When you play the next note, all of the pitches between the first note and the second note will be played, stopping at the second note.",
            "links": []
        },

        "reverb" : {
          "word": "Reverb",
          "definition": "Reverb is ambient noise produced by the reflections of a sound source within an enclosed space. There are two things to watch out for when using reverb. 1. Reverb can pull an instrument or track back into the mix. If you use too much on an important track, your track won't stand out from the rest of the mix as much as you'd like. There are a couple of techniques you can do to avoid this. Don't overdo it on the reverb. Plain and simple. Sometimes it is best for the reverb to be more of a psycho-acoustic effect, such that the reverb itself is difficult to notice until it is removed. Find a sweet spot for the reverb. Another thing you can do is use a delay instead of a reverb. Delays can give you a reverb-like sound without pulling the track back from the forefront of the mix. 2. Using too much reverb will add mud to your mix and put more strain on your CPU when using your DAW. Most of the time, you shouldn't put reverbs on everything and you should adjust the reverb parameters such that you don't have tons of sustained reflections everywhere, clouding up your mix. A good technique is to have one or two reverb buses. Reverb buses can prevent you from overloading your CPU, since you won't have like 20 reverb VSTs on 20 different tracks. They will also tie/glue your mix together. Instruments will feel as if they are being played within the same space. And above all, it makes your life easier. Rather than having to adjust 1000 different knobs on different reverb VSTs, you have one consistent place where you can play with the reverb parameters.",
          "links": [
            {
              "title": "Reverb Reference",
              "link": "https://www.izotope.com/en/learn/reflecting-on-reverb-what-it-is-and-how-to-use-it.html"
            },
            {
              "title": "Reverb vs Delay. When to use Each one.",
              "link": "https://www.izotope.com/en/learn/when-to-use-reverb-and-delay.html"
            },
            {
              "title": "How to Use Reverb Like a Pro - 3 Simple Tips for 3D Mixes",
              "link": "https://www.musicianonamission.com/how-to-use-reverb/"
            },
            {
              "title": "FL STUDIO | Mixing Basics - Reverbs",
              "link": "https://www.youtube.com/watch?v=hFRwk1LOdBU&list=PLkYsB0Ki9lAdIaYCpB0B0uVTZMZBt9NdX&index=6&ab_channel=FLSTUDIObyImage-LineSoftware"
            }
          ]
        },
        "ribbonmic": {
            "word": "Ribbon Microphone",
            "definition": "Ribbon microphones are similar to dynamic mics in the method of recording. There is a diaphragm that sits within a magnetic field. The magnetic field induces voltages according to how the diaphragm moves. However, in this case, the diaphragm is a long and thin metcallic ribbon that sits within the magnetic field. The vibration of this ribbon within the magnetic field induces changes in voltage within the ribbon circuit, allowing us to record sound. The ribbons are very low mass systems and can vibrate along with high frequency sources. This means they have wider and flatter frequency responses that dynamic mics do. There are some downsides to these mics. They are excellent at picking up minute details, but their outputs are very limited. You typically need some sort of transformer or large-gain pre-amplifier to use these mics. Due to the fragility of the ribbon, this mic is also not very durable. A loud sound or physical impact can break this ribbon and ruin the microphone.",
            "links": [
              {
                "title": "Audio Recording Tutorial - Comparing microphone types",
                "link": "https://www.youtube.com/watch?v=2edewYkE_f0&ab_channel=LinkedInLearning"
              },
              {
                "title": "Roswell Pro Audio - How Ribbon Mics Work",
                "link": "https://www.youtube.com/watch?v=BOAh0OVuxSA&ab_channel=RoswellProAudio"
              }
            ]
        },
        "side" : {
          "word": "Side",
          "definition": "Within the context of stereomixing, side is the audio that is different between the left and right stereo channels. The side manifests itself as a surrounding separated stereo space where the user can hear differences in timing and loudness between either ear. It is typically not as loud or intense as the mid.",
          "links": [
            {
              "title": "Izotope - Stereo Imaging in Mastering: Width and Mid/Side | Are You Listening? | S2 Ep1",
              "link": "https://www.youtube.com/watch?v=0tqlHNuacik&ab_channel=iZotope%2CInc."
            },
            {
              "title": "In the Mix - Mid Side EQ Simplified - A Powerful Tool for Stereo Mixing",
              "link": "https://www.youtube.com/watch?v=kEiILPm1VSc&ab_channel=InTheMix"
            }
          ]
        },
        "staccato" : {
          "word": "Staccato",
          "definition": "Staccato is a form of musical articulation. In modern notation, it signifies a note of shortened duration, separated from the note that may follow by silence.",
          "links": [
            {
              "title": "Video with sound demonstration",
              "link": "https://www.youtube.com/watch?v=JgJcKt92vt8&ab_channel=LearnPianoCompleteGuide"
            },
            {
              "title": "Staccato-Wikipedia",
              "link": "https://en.wikipedia.org/wiki/Staccato"
            }
          ]
        },
        "stem" : {
          "word": "Stem",
          "definition": "A stem is a subcomponent of a mix that consists of various sounds and effects all combined into a single file or track. The stems are not individual elements of a mix, but combinations of them. Stems are derived from a mix as a whole and split up in whatever manner makes sense to you. A good example is an orchestra. You could split it up into strings, brass, vocals, drums, etc. Each of these groups are a stem. Notice that each group is not made up of a single element or instrument. However, note that it makes sense to create a stem from a single instrument, but that stem would also include all the effects on that instrument, like reverb. There are many reasons to split up a musical work into stems, like splitting up a finished mix into stems, passing the stems to a mastering engineer, and giving them a little more freedom to balance certain elements of the song. This gives the mastering engineer more granular control over the mix, but not TOO granular. Check out the article linked below for more info.",
          "links": [
            {
              "title": "Stems In Music Production - Everything You Need To Know",
              "link": "https://www.pro-tools-expert.com/production-expert-1/2020/7/6/stems-in-music-production"
            }
          ]
        },
        "stockplugins" : {
          "word": "Stock Plugins",
          "definition": "These are the plugins that come with your DAW or that are typically free. The other option are 3rd party or paid pro plugins. These days, stock plugins are usually fantastic and if you're a good enough audio engineer, you can make a great mix with these plugins. There are also TONS of free, 3rd party plugins out on the market now, so the necessity of having pro-level plugins is dying out. That being said, pro-plugins are typically beuatifully designed and offer more functionality than stock plugins typically do. So it usually is nice to work with one. I categorize paid, pro plugins into two slots. Either they are plugins that offer more controls and features than other free plugins (they have more bells and whistles) or they are in a much more specialized space where stock plugins aren't as competitive. In the first case, you can think of an EQ. There are thousands of free EQs out there, but there are also paid versions. You can more than get by on an EQ stock plugin, but there may be some pro EQs on the market that offer better monitoring, more control granularity, dynamics controls, or that impart some sort of analog mark on the sound that isn't found anywhere else. Like I said you don't NEED pro plugins to be a great audio engineer these days, so it's up to you whether the added features are worth the money you have to put forward to buy them. The other category for pro plugins is plugins that are within a niche space where stock plugins just aren't nearly as good or as competitive. An example that comes to mind is pitch correction. There is competition in pitch correction, like Waves Tune versus Autotune, but you're not going to find much competition in that category from stock plugins. In a case like that, I would recommend dropping some money because there aren't as many stock plugins around in that category. The ones that are around may not be able to compete or produce nearly as good of a result as pro plugins. (Side Note: Being a programmer myself, I know how much work goes into creating and maintaining these plugins. Even for the free 3rd party plugins, if you have the money or make some money using them, it would be super cool to donate a little bit to developers of the plugin. I'm sure it would go a long way for them.)",
          "links": [
            {
              "title": "In the Mix - Can You Hear The Difference? Stock EQ vs Pro EQ",
              "link": "https://www.youtube.com/watch?v=jr-0KNGiuyA&t=5s&ab_channel=InTheMix"
            }
          ]
        },
        "synthesis" : {
          "word": "Synthesis",
          "definition": "The creation of different sounds, typically through the use of a synthesizer. There are different kinds of synthesis, like additive synthesis, in which a unique sound is created by adding together modulated waveforms from different sources/oscillators.\n\nSynthesizers vary, but many of them include a set of standard tools that you can use for synthesis: LFOs, ADSR/Transient ramp modulators, AM, FM, PM, & Ring modulators, and oscillators (sine, square, sawtooth, triangle, etc...). These tools give you a lot of flexibility to manipulate every aspect of a waveform and its corresponding sound.",
          "links": [
            {
              "title": "Learning Synthesis (In-depth tutorial on PerfectCircuit.com)",
              "link": "https://www.perfectcircuit.com/signal/learn-synthesis"
            }
          ]
        },
        "trscable": {
            "word": "TS/TRS Cable",
            "definition": "TS cables are unbalanced cables that are used to carry sound signals.",
            "links": [
              {
                "title": "A Complete Guide to Gain Staging",
                "link": "https://www.youtube.com/watch?v=Tq5lDHCKt84&t=133s&ab_channel=MusicianonaMission"
              }
            ]
        },
        "volumeriding": {
            "word": "Volume/Fader Riding",
            "definition": "This is also known as Volume Automation. The term riding comes from physically moving up, or riding, your faders. The whole point of this technique is to create or reduce energy within a song and direct the user's attention to a certain element in a track. This technique is definitely a cherry on top of your mix. It is not essential, but sprinkling some volume automation throughout your mix can really set you apart and push you past that line to the next level. Listen to your mix. If there are certain instruments that you feel should be louder in some portions of the track, even if it's for a second, then bring them up. This helps create energy, fill empty space, and direct the user to focus on that particular element. You can do this by hand or add automation in your DAW to do this.",
            "links": [
              {
                "title": "Bring Energy and Dynamics to Your Mix With Volume Fader Rides",
                "link": "https://www.recordingrevolution.com/bring-energy-and-dynamics-to-your-mix-with-volume-fader-rides-video/"
              },
              {
                "title": "How to Hook the Listener with Volume Automation",
                "link": "https://www.musicianonamission.com/hook-listener-volume-automation/"
              },
              {
                "title": "(Discussion) How is a Compressor different from Gain/Fader Riding?",
                "link": "https://music.stackexchange.com/questions/106688/how-is-a-compressor-different-from-gain-fader-riding"
              }
            ]
        },
        "volume": {
            "word": "Volume",
            "definition": "Volume is the level of a signal (generally in dB) at the end of a signal chain (after all of your processing). You control how much of this eventually makes it into the mix using faders on your mixing console. Contrast this with gain, which is the level of the signal before going through the signal chain. It is important to note that this is a contextual definition. Not everyone will go by this convention and volume and gain can be used interchangebly and to label different things. This distinction between volume and gain is good to have when you're doing something like gain staging.",
            "links": [
              {
                "title": "A Complete Guide to Gain Staging",
                "link": "https://www.youtube.com/watch?v=Tq5lDHCKt84&t=133s&ab_channel=MusicianonaMission"
              }
            ]
        },
        "vst": {
            "word": "VST/VST2/VST3",
            "definition": "Standing for Virtual Studio Technology, this is a type of audio processing plugin API standard invented by Steinberg back in 1996. People will develop a digital signal processing backend along with a GUI in order to emulate old analog hardware or create a new, original digital plugin. If the software fits within the constraints of the VST standard, then it can be used as either a standalone plugin or within a DAW. These plugins can be effects, generators, visual effects, monitoring, etc. Basically anything you want related to audio. The standard has gone through several iterations. It is currently sitting at VST3. Each of these iterations has introduced more features and capabilities to the standard. Any 3rd party can create and distribute a VST plugin, as long as you fit within the standard's constraints. Please note that there are other virtual studio or plugin standards around, like apple's AU, Pro Tools' AAX, or Linux's LADSPA.",
            "links": [
              {
                "title": "Lifewire - What Are VST Plugins and What Do They Do?",
                "link": "https://www.lifewire.com/what-are-vst-plugins-4177517"
              },
              {
                "title": "Wikipedia - VST",
                "link": "https://en.wikipedia.org/wiki/Virtual_Studio_Technology"
              },
              {
                "title": "What is the difference between VST2 and VST3 audio plugins?",
                "link": "https://www.quora.com/What-is-the-difference-between-VST2-and-VST3-audio-plugins"
              },
              {
                "title": "VST Resources",
                "link": "https://docs.lmms.io/user-manual/7-resources/7.6-vst-resources"
              },
              {
                "title": "VST Resources",
                "link": "https://docs.lmms.io/user-manual/7-resources/7.6-vst-resources"
              },
              {
                "title": "Wikipedia - LADSPA",
                "link": "https://en.wikipedia.org/wiki/LADSPA"
              },
              {
                "title": "LADSPA Home Page",
                "link": "https://www.ladspa.org/"
              },
              {
                "title": "Wikipedia - Audio Units (AU)",
                "link": "https://en.wikipedia.org/wiki/Audio_Units"
              },
              {
                "title": "Musician Wave - The Differences Between VST 2 and VST 3",
                "link": "https://www.musicianwave.com/vst2-vst3-differences/#:~:text=VST3%20is%20designed%20so%20that,at%20that%20point%20in%20time."
              }
            ]
        },
        "xlrcable": {
            "word": "XLR Cable",
            "definition": "These cables carry sound data and are known for being high-quality and noise resistant. XLR cables are balanced. This means they have 2 separate lines for carrying the sound signal. One carries the normal signal, and the other line carries an inverted version of the sounds signal. On the other end, the audio receiver will flip the inverted signal back, add it to the regular signal, and divide by 2. All of this is done to prevent noise. Electromagnetic interference will induce noise within both the regular and inverted lines. This noise will be the same in both lines. When you get to the audio receiver, one of the noise signals will be inverted and perfectly cancel out the noise in the other line. This setup minimizes noise introduced by EMI. XLR cables are also set up to deliver phantom power, which is require by condensor mics. They also have a nice latch on either end that keeps the cable from falling off.",
            "links": [
              {
                "title": "Lewitt - What is XLR?",
                "link": "https://www.youtube.com/watch?v=ZaHgyJ8v_jc&ab_channel=LEWITT"
              },
              {
                "title": "Beginner’s guide to connecting audio cables (XLR, TRS, Hi-Z)",
                "link": "https://www.youtube.com/watch?v=DSjeLsPj-Lc&ab_channel=PeteJohns-StudioLiveToday"
              }
            ]
        },
        "zynaddsubfx" : {
          "word": "ZynAddSubFX",
          "definition": "A very versatile synth that comes pre-installed with LMMS. It has workflows for additive, subtractive, and PAD synthesis. Please note that I am referring to the older version of this tool. There is a newer, premium version called Zyn-Fusion.",
          "links": [
            {
              "title": "ZynAddSubFX Manual/Wiki Site",
              "link": "https://wiki.linuxaudio.org/wiki/zynaddsubfx_manual"
            },
            {
              "title": "LMMS ZynAddSubFX Video Tutorials (Section 7.3.5.3)",
              "link": "https://docs.lmms.io/user-manual/7-resources/7.3-video-tutorials"
            },
            {
              "title": "ZynAddSubFX Oscillator API",
              "link": "https://zynaddsubfx.sourceforge.io/zyn-ports/#"
            },
            {
              "title": "ZynAddSubFX Info Document",
              "link": "http://lac.zkm.de/2005/papers/nasca_octavian_paul.pdf"
            }
          ]
        }
    }
}
